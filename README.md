# Natasha Muromcew's DataVis Portfolio

This is my portfolio for Term 2 of CSC630: Data Visualizations. Here you can view all of work including my group projects, individual project, final project, and homework assignemnts. 



# Final Project:

For the final project our assignment was to create a data visualization that could be placed on the large touchscreen in the library basement. When brainstorming how to make good use of such a public and interactive screen, I was inspired by JKE's words asking us as an Andover community to do better. I thought about how I could make a visualization that could spread positivity and lift the spirits of the student body. Working with Chenault Ellis and Claire de Saint Phalle, we came up with the idea of a compliment wall. We used Google Docs to build a survey that collected compliments, emails, and data on the compliments and put the recieved data into a Google Spreadsheet. We used StreamLit, Github, and Python to build a StreamLit App that shows a QR code for students to fill out the survey, recent compliments, and visualizations of the data collected. In order to collect data before the project was public, we asked our friends to fill out the survey and the results have been extremely positive. 

Link to StreamLit [here](https://share.streamlit.io/natasha-muromceww/finalproject/main/StreamLitVis.py). 
Link to Project Repository [here](https://github.com/natasha-muromceww/FinalProject). 

Photo 1:

![..](https://github.com/natasha-muromceww/DataVisPortfolio/blob/main/FinalProjectPhoto1.png)

Photo 2:

![..](https://github.com/natasha-muromceww/DataVisPortfolio/blob/main/FinalProjectPhoto2.png)


# Individual Project:

For the Individual Project I made a visulization of how many classes are held in each building during each class period of the day. I used Python and StreamLit to build a geomap of Andover with 3D visulizations for each building. On StreamLit the user can use the silder to view each period, scroll down for a photo comparison between each period. I collected data from the Winter Term 2022 Master Schedule and used tutorials on the StreamLit documentation (link: https://docs.streamlit.io/). 

Link to StreamLit is [here](https://share.streamlit.io/natasha-muromceww/individual-project/main/BuildingUsageVisualization.py) and link to my code is [here](https://github.com/natasha-muromceww/Individual-Project/blob/main/BuildingUsageVisualization.py). 

Link to the Individual Project Repository [here](https://github.com/natasha-muromceww/Individual-Project). 



# Group Projects:
## Addison Group Task

Our first group task was to use data from the Addison Gallery of American Art to create a visulization. I worked with Claire de Saint Phalle to do an exploratory data analysis of the csv and xls files provided by the Addison Gallery of American Art to find a question, answer it, and make a physical/visual representation of that answer. Claire and I questioned the distribution among medium types in the Addison collection and answered it through a pie chart, distribution table, and physical representation of amount of mediums using photos from the Addison website. The chart is a documentation of our data and calculations used to make the final product. We listed the type, amount, percentage, the calulation used to make a scaled visual repesentation, and the dimensions per medium on the project. We divided all of the calculations by 6 to scale it. For the final representation we used collages of photos from the Addison arranged in squares representative of the percentage each medium. We found it surprising how many photographs and printes there were becuase those two categories made up about 65% of the collection.

Link to Addison Group Task Repository for additional documentation [here](https://github.com/natasha-muromceww/Addison-Group-Task). 

Link to the Jupyter notebook used [here](https://github.com/natasha-muromceww/Addison-Group-Task/blob/main/Addison%20Data.ipynb). 

Our final representation:
![...](https://github.com/natasha-muromceww/Addison-Group-Task/blob/main/Screen%20Shot%202021-12-15%20at%2011.31.51%20AM.png)


## Extant Visualization Group Task

For the second group task I worked with Claire de Saint Phalle to examine data visualizations by position, size, shape, value, color, orientation, and texture as learned about in a previously done reading about variables in data visualizations linked [here](https://prism.ucalgary.ca/handle/1880/45758). For the first part of the project we found data visualzations that fell under these seven categories. The second part of the project was to create our own set of seven visualizations following the same categories using one dataset. Claire and I used a dataset on Twitter revenue linked [here](https://www.businessofapps.com/data/twitter-statistics/). The third part of this project was to partner with another group and make a new set of seven visualizations uing their data and a new set of "marks" per visualization. We partnered with Dakota Change and Sofia Marina and worked with their visualizations on apple production. 

Link to repository with all 21 data visualizations [here](https://github.com/natasha-muromceww/Group-Task-2). 


## Group task 3: Misleading Graphs 

For the third group task I worked with Brian Masse on a political tweet ananlysis. We used a political tweet dataset linked [here](https://github.com/Brian-Masse/Political-Tweet-Analysis/tree/main/PART%20II/data) to create two data visualizations, one that was clear and easy to read and one that was purposefully hard to understand or misleading. We aimed to find the relationship between target audience and the contents of the tweets. Part of the work in making a visulization good or bad came in the formatting and presentation aspect of it, such as colors, labeling, and font readbility. The other half came form the way the numbers were manipulated in the visualization. So, for a good visulization, we kept he numbers as clean as possible in a "part-to-whole" format where as in the bad visualization we inverted the numbers to purposefully miselad wihtout changeing the raw data. 

Link to full project repository [here](https://github.com/Brian-Masse/Political-Tweet-Analysis/tree/main/PART%20II). 



# Homework Assignments: 

These homework assignments followed the #30DayChartChallenge for which we created a new data visualization before each class. I used a combination of python, jupyter notebook, photoshop, and pandas, plotly, and more to create these. The data sources are linked below each respective visualization. 

## Day 1: part-to-whole 
### iPhone Screentime 11/28 - 12/4
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/ScreentimePieChartWeek1.png)

### iPhone Screentime 11/21 - 11/27
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/NatashaScreenTimePieChartWeek2.png)

### iPhone Screentime 11/14 - 11/20
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/NatashaScreentimePieChartWeek3.png)

For this assignment, I used pie charts to compare my screentime divided among apps on my phone. I used pandas and a Jupuyter notebook to code the charts.

Jupyter Notebook code [here.](https://github.com/natasha-muromceww/DataVis1/blob/main/NatashaScreentime.ipynb) 
Link to the source I used to learn how to use pandas for pie charts [here.](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)

## Day 2: Pictogram
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/pictogram.png)

This assignment was to create a pictogram. I chose to represent the number of items in my closet by type (tops, bottoms, accessories, outerwear, and shoes). This is per my most recent count, which was the end of last spring. Each season I log all of the items in my closet and atempt to track the frequency of each item worn. I was not very consitent in tracking that last fall but I do have a near perfect consistency logging my clothing from last Spring and it's great to have a chance to use that data (link to data [here](https://docs.google.com/spreadsheets/d/1B0-v3ouY4rN1e4tSHUbPqobK7eeLLzmpLQm02g24KoE/edit?usp=sharing). I used a tutorial from Towards Data Science (link found [here](https://towardsdatascience.com/2-efficient-ways-of-creating-fancy-pictogram-charts-in-python-8b77d361d500)) and the pywaffle documentation (link found [here](https://pywaffle.readthedocs.io/en/latest/)) to create this pictogram using a jupyter notebook and python (jupyter notebook found [here](https://github.com/natasha-muromceww/DataVis1/blob/main/DataVis%20Pictogram%20(1).ipynb)). I could've used a more simle program like a pictogram creator online but I wanted more control. Even though it did not go perfectly, I still had a lot of choice with the set up and color choices. I tried my very best to use clothing icons but none of them were working with my code so eventually, at around 2:00 am, I gave up and settled on more basic icons. In the future I would like to learn how to use to more advanced icons in pywaffles but. 

## Day 3: Pictogram pt. 2
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/PictogramTops.png)
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/PictogramBottoms.png)
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/PictogramShoes.png) 
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/PictogramOuterwear.png)
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/PictogramAccessories.png) 

This assignemnt was to create another pictogram. This time I compared the amount of items worn and not worn for each type of item in my closet (tops, bottoms, shoes, outerwear, accessories). I used the same data from the last assignemnt (link to data [here](https://docs.google.com/spreadsheets/d/1B0-v3ouY4rN1e4tSHUbPqobK7eeLLzmpLQm02g24KoE/edit?usp=sharing)). I used a tutorial from Towards Data Science (link found [here](https://towardsdatascience.com/2-efficient-ways-of-creating-fancy-pictogram-charts-in-python-8b77d361d500)) and the pywaffle documentation (link found [here](https://pywaffle.readthedocs.io/en/latest/)) to create this pictogram using a jupyter notebook and python (jupyter notebook found [here](https://github.com/natasha-muromceww/DataVis1/blob/main/DataVis%20Pictogram2.ipynb)). 

## Day 4: Historical Comparison
![..](https://github.com/natasha-muromceww/DataVis1/blob/main/HistoricalComparison.png)

This assignment was to make a historical comparison. I used the sleep data from my garmin watch, a matplotlib tutorial (link [here](https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html)) and a jupyter notebook 
(found [here](https://github.com/natasha-muromceww/DataVis1/blob/main/HistoricalComparison%20.ipynb)). 

## Day 5: Magical Comparison
![...](https://github.com/natasha-muromceww/Group-Task-2/blob/main/Box%20Office%20Revenue%20%20vs.%20Movie%20.png)

This assignment was to make a "Magical Comparison", the guidelines were pretty broad so I decided to chart data about the number one thing that comes to mind when I think of Magic, Harry Potter. This is a histogram comparing box office revenue between the 8 movies. 
Link to data source [here](https://www.the-numbers.com/movies/franchise/Harry-Potter#tab=summary). 

## Day 6: Slope Comparison
![...](https://github.com/natasha-muromceww/Group-Task-2/blob/main/Calories%20burned%20at%20the%20gym%20over%2030%20days%20.png)

This assignment was to make a slope comparison, I compared calories burned at the gym over 30 days using data from my Garmin Watch. 

## Day 7: Experimental Comparison 
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/Odds%20and%20Result%20Attempts%20.png)
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/Result%20Attempts%20.png)

This assignment was open ended so I looked at data from The Infinite Monkey Theorem Experiment. I thought it would be interesting to look at because the experiment itself is pretty ridiculous and doesn't proved very many results. I compared a few different numbers however the data is hard to view because the range is so large. Data found [here](https://data.world/the-pudding/the-infinite-monkey-theorem-experiment). 

## Day 8: Physical Distribution
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/physical%20distribution.png)

This assignment was to create a physical distribution. I used data from my 2021 closet spreadsheet to represent the amount of tops in my wardrobe I wore during the Spring. 

## Day 9: Animal Distribution
![...](https://github.com/natasha-muromceww/DataVis1/blob/main/Day%209_%20Animal%20Distribution.jpg)

WHen I thought of animals I thought of bugs because there are so many species. I used data from Wikipeida to compare the different amounts of species to their bug orders(a section of bug type) using image size comparison. 
Link to source [here](https://en.wikipedia.org/wiki/Insect). 

## Day 10: Distribution - Statistics


## Day 11: Abstract Distribution

## Day 12: Circular Distribution

## Day 13: Strip Distribution

## Day 14: Correlation

## Day 15: Space

## Day 16: Multivariate
